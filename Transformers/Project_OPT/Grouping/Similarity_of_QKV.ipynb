{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qik7VX9K2MND","executionInfo":{"status":"ok","timestamp":1753554205070,"user_tz":-180,"elapsed":47567,"user":{"displayName":"idan הפנר","userId":"11408105555936530563"}},"outputId":"a16cc27a-98ec-4325-b030-b3b107bf3c3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["! pip install -q transformers==4.52.2\n","! pip install -q -U datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XlYMTE-C2e5L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753554703726,"user_tz":-180,"elapsed":3258,"user":{"displayName":"idan הפנר","userId":"11408105555936530563"}},"outputId":"6897e0ef-edd7-4dc3-f148-2dc9789a7ac4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OcYT6bHx2m3y"},"outputs":[],"source":["import os\n","import torch\n","from datasets import load_dataset\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","from datasets import load_dataset\n","from torch import nn\n","from transformers.models.opt.modeling_opt import OPTAttention\n","\n","import sys\n","sys.path.append('/content/drive/MyDrive/Transformers/Project_OPT/Grouping')\n","\n","! pip install -q k_means_constrained\n","from Grouping_Utils import close_by_w, close_by_attention_score, plot_layer_head_similarity"]},{"cell_type":"markdown","metadata":{"id":"CMdfO2zAG6IL"},"source":["# **Load Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"paWEBohE2oJj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753554785951,"user_tz":-180,"elapsed":24298,"user":{"displayName":"idan הפנר","userId":"11408105555936530563"}},"outputId":"cc6dd7d6-ed0f-4232-882d-08714161988d"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at facebook/opt-1.3b and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["OPTForSequenceClassification(\n","  (model): OPTModel(\n","    (decoder): OPTDecoder(\n","      (embed_tokens): Embedding(50272, 2048, padding_idx=1)\n","      (embed_positions): OPTLearnedPositionalEmbedding(2050, 2048)\n","      (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n","      (layers): ModuleList(\n","        (0-23): 24 x OPTDecoderLayer(\n","          (self_attn): OPTAttention(\n","            (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n","            (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n","            (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n","            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n","          )\n","          (activation_fn): ReLU()\n","          (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n","          (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n","          (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (score): Linear(in_features=2048, out_features=3, bias=False)\n",")"]},"metadata":{},"execution_count":3}],"source":["n_heads = 32\n","kv_heads = 32\n","\n","repo_name = \"facebook/opt-1.3b\"\n","model = AutoModelForSequenceClassification.from_pretrained(\n","   repo_name, num_labels=3, device_map=\"cpu\",\n",")\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ujdsgMT3pL7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753554785970,"user_tz":-180,"elapsed":21,"user":{"displayName":"idan הפנר","userId":"11408105555936530563"}},"outputId":"f85b7748-63fa-4c72-da63-e9a46e28be68"},"outputs":[{"output_type":"stream","name":"stdout","text":["5263.056896\n"]},{"output_type":"execute_result","data":{"text/plain":["OPTForSequenceClassification(\n","  (model): OPTModel(\n","    (decoder): OPTDecoder(\n","      (embed_tokens): Embedding(50272, 2048, padding_idx=1)\n","      (embed_positions): OPTLearnedPositionalEmbedding(2050, 2048)\n","      (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n","      (layers): ModuleList(\n","        (0-23): 24 x OPTDecoderLayer(\n","          (self_attn): OPTAttention(\n","            (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n","            (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n","            (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n","            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n","          )\n","          (activation_fn): ReLU()\n","          (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n","          (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n","          (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (score): Linear(in_features=2048, out_features=3, bias=False)\n",")"]},"metadata":{},"execution_count":4}],"source":["print(model.get_memory_footprint()/1e6)\n","model"]},{"cell_type":"markdown","metadata":{"id":"PDeyBdunHGFe"},"source":["# **Plot heads per layer similarity**\n","By generating random input x, the similarity score will be obtained from the Wk/Wq/Wv times x output."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pAU-toFfMDGA"},"outputs":[],"source":["layer_idx = 0\n","total_grouping = []\n","\n","for name, module in model.model.decoder.named_modules():\n","  if isinstance(module, OPTAttention):\n","    kvq_w = module.q_proj.weight.data\n","    layer_grouping, _ = close_by_w(kvq_w, n_heads, kv_heads, layer_idx, group_size=2)\n","    total_grouping.append(layer_grouping)\n","    layer_idx += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HNanT6puPILW"},"outputs":[],"source":["l = [arr.astype(int).tolist() for arr in total_grouping]\n","print(l)"]},{"cell_type":"markdown","metadata":{"id":"aufiWyiQzakS"},"source":["# **By sampling input from the validation set of MNLI**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5630,"status":"ok","timestamp":1753442329036,"user":{"displayName":"idan הפנר","userId":"11408105555936530563"},"user_tz":-180},"id":"7unv5auo8Wzh","outputId":"2e7b4f7f-b5b4-40d7-ed00-b0431662df92"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 392702\n","    })\n","    validation_matched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 9815\n","    })\n","    validation_mismatched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 9832\n","    })\n","    test_matched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 9796\n","    })\n","    test_mismatched: Dataset({\n","        features: ['premise', 'hypothesis', 'label', 'idx'],\n","        num_rows: 9847\n","    })\n","})"]},"metadata":{},"execution_count":5}],"source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"nyu-mll/glue\", \"mnli\")\n","\n","tokenizer = AutoTokenizer.from_pretrained(repo_name)\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tem8RGJI2uXO"},"outputs":[],"source":["dataset[\"train\"] = dataset[\"train\"].shuffle(seed=42).select(range(50000))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["4c6628bc7ce04157903d73576c449519","8264e76a71ce4a62b5144348bb2249e1","744e34fa02b140d8af35fb0600a65239","67747e5d41ab427d805e8260035bf58a","c55eba72ba104ef78808318204ca3153","6dc91993b9e6485ab1b62926960cf238","5a7fb6c272c44bf987508c7a45c1afb1","0a49f0ab9ab848598a3fe7db020169d8","e6f1748e2a6c4885b77ec4115cff7254","1dd6db99856f464e975881beb5a6f9e0","ae7915e0119e43ed8211c42317f777f0"]},"executionInfo":{"elapsed":1313,"status":"ok","timestamp":1753442330384,"user":{"displayName":"idan הפנר","userId":"11408105555936530563"},"user_tz":-180},"id":"BcGjE5Cl3Emt","outputId":"845d022e-bdff-4837-acc3-ddab603c2686"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/9847 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c6628bc7ce04157903d73576c449519"}},"metadata":{}}],"source":["def preprocess(example):\n","    return tokenizer(\n","        example[\"premise\"],\n","        example[\"hypothesis\"],\n","        truncation=True,\n","        padding=\"max_length\",\n","        max_length=128,\n","    )\n","\n","encoded_dataset = dataset.map(preprocess, batched=True)\n","encoded_dataset = encoded_dataset.rename_column(\"label\", \"labels\")\n","encoded_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h_6A-3aBBX50"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from transformers.models.opt.modeling_opt import OPTAttention\n","\n","def capture_projection2(model, input_ids, attention_mask, n_heads, proj_type=\"q\"):\n","    captured = []\n","\n","    def save_output(module, input, output):\n","        # output is the projected tensor (batch, seq_len, hidden_dim)\n","        captured.append(output.detach())\n","\n","    hooks = []\n","    for name, module in model.model.decoder.named_modules():\n","        if isinstance(module, torch.nn.Linear) and name.endswith(f\"{proj_type}_proj\"):\n","            hooks.append(module.register_forward_hook(save_output))\n","\n","    with torch.no_grad():\n","        model(input_ids=input_ids, attention_mask=attention_mask)\n","\n","    for h in hooks:\n","        h.remove()\n","\n","    # Reshape for heads\n","    for i in range(len(captured)):\n","        d = captured[i].shape[-1] // n_heads\n","        captured[i] = captured[i].view(captured[i].shape[0], -1, n_heads, d).transpose(1, 2)\n","\n","    print(f\"Captured {proj_type}-projection from {len(captured)} layers.\")\n","    print(\"Shape of first capture:\", captured[0].shape)\n","    return captured\n","\n","# Example use\n","sample = encoded_dataset[\"validation_matched\"][0]\n","input_ids = sample[\"input_ids\"].unsqueeze(0).clone().detach()\n","attention_mask = sample[\"attention_mask\"].unsqueeze(0).clone().detach()\n","\n","final_out = []\n","\n","for idx in range(10):\n","    sample = encoded_dataset[\"validation_matched\"][idx]\n","    input_ids = sample[\"input_ids\"].unsqueeze(0).clone().detach()\n","    attention_mask = sample[\"attention_mask\"].unsqueeze(0).clone().detach()\n","\n","    q_out = capture_projection2(model, input_ids, attention_mask, n_heads, proj_type=\"q\")\n","\n","    if not final_out:\n","        final_out = q_out\n","    else:\n","        for j in range(len(q_out)):\n","            final_out[j] = torch.cat((final_out[j], q_out[j]), dim=2)\n","\n","print(\"Final shape of first layer's k projection:\", final_out[0].shape)"]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","def plot_layer_head_similarity(outs):\n","    for layer_idx, k_proj in enumerate(outs):\n","        k_proj = k_proj.squeeze(0)  # (n_heads, seq_len, d_kv)\n","        n_heads, seq_len, d_kv = k_proj.shape\n","\n","        sim_matrix = torch.zeros((n_heads, n_heads))\n","\n","        for t in range(seq_len):\n","            k_vectors = k_proj[:, t, :]  # (n_heads, d_kv)\n","            k_norm = F.normalize(k_vectors, dim=1)  # normalize each head's vector\n","\n","            cos_sim = torch.matmul(k_norm, k_norm.T)  # → (n_heads, n_heads)\n","            sim_matrix += cos_sim\n","\n","        # Average across sequence length\n","        sim_matrix /= seq_len\n","        sim_matrix_np = sim_matrix.cpu().numpy()\n","\n","        plt.figure(figsize=(6, 5))\n","        sns.heatmap(sim_matrix_np, cmap='coolwarm', vmin=-1, vmax=1,\n","                    xticklabels=[f\"H{i}\" for i in range(n_heads)],\n","                    yticklabels=[f\"H{i}\" for i in range(n_heads)])\n","        plt.title(f\"Layer {layer_idx} - Head-to-Head K Cosine Similarity\")\n","        plt.xlabel(\"Head\")\n","        plt.ylabel(\"Head\")\n","        plt.tight_layout()\n","        plt.show()\n","\n","plot_layer_head_similarity(q_out)"],"metadata":{"id":"7Xb1Y61SLaGt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from Grouping_Utils import close_wk, plot_layer_head_similarity, process_grouping\n","\n","total_grouping = []\n","\n","for layer in range(len(q_out)):\n","  grouping = plot_layer_head_similarity(q_out[layer], layer, 2)\n","  grouping = process_grouping(grouping, n_heads)\n","\n","  total_grouping.append(grouping)\n","\n","\n","l = [arr.astype(int).tolist() for arr in total_grouping]\n","print(l)"],"metadata":{"id":"R89PFYrrTyxA"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["CMdfO2zAG6IL","PDeyBdunHGFe","aufiWyiQzakS"],"authorship_tag":"ABX9TyOPdiGASVT4qU8xEmC23oN6"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"4c6628bc7ce04157903d73576c449519":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8264e76a71ce4a62b5144348bb2249e1","IPY_MODEL_744e34fa02b140d8af35fb0600a65239","IPY_MODEL_67747e5d41ab427d805e8260035bf58a"],"layout":"IPY_MODEL_c55eba72ba104ef78808318204ca3153"}},"8264e76a71ce4a62b5144348bb2249e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6dc91993b9e6485ab1b62926960cf238","placeholder":"​","style":"IPY_MODEL_5a7fb6c272c44bf987508c7a45c1afb1","value":"Map: 100%"}},"744e34fa02b140d8af35fb0600a65239":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a49f0ab9ab848598a3fe7db020169d8","max":9847,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e6f1748e2a6c4885b77ec4115cff7254","value":9847}},"67747e5d41ab427d805e8260035bf58a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1dd6db99856f464e975881beb5a6f9e0","placeholder":"​","style":"IPY_MODEL_ae7915e0119e43ed8211c42317f777f0","value":" 9847/9847 [00:01&lt;00:00, 6701.96 examples/s]"}},"c55eba72ba104ef78808318204ca3153":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dc91993b9e6485ab1b62926960cf238":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a7fb6c272c44bf987508c7a45c1afb1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a49f0ab9ab848598a3fe7db020169d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6f1748e2a6c4885b77ec4115cff7254":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1dd6db99856f464e975881beb5a6f9e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae7915e0119e43ed8211c42317f777f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}